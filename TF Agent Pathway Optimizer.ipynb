{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9851de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import basicGridModel\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b0c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19c5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8f92a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 10, 10,  5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = basicGridModel.discretePath3(20,20) # Grid Size\n",
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8798515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "env.cmd_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff7588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'discretePath3' object has no attribute 'time_step_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1a88c5be0215>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Observation Spec:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_step_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'discretePath3' object has no attribute 'time_step_spec'"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4984d731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "509cbe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcbc6a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([-0.01982621, -0.03738579, -0.04698693,  0.04392102], dtype=float32),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0)})\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([-0.02057393,  0.15837733, -0.04610851, -0.26320866], dtype=float32),\n",
      " 'reward': array(1., dtype=float32),\n",
      " 'step_type': array(1)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5565ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name) #For Training\n",
    "eval_py_env = suite_gym.load(env_name) # For Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2294cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b9797b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# it's output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14161c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "313480f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3885bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b00148f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_environment = tf_py_environment.TFPyEnvironment(\n",
    "    suite_gym.load('CartPole-v0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "985c8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = example_environment.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "188a76d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0], dtype=int64)>, state=(), info=())"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_policy.action(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2f67c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19e5a71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1633f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab44604d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
       "      dtype=float32)),\n",
       " 'policy_info': (),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0527cee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('step_type',\n",
       " 'observation',\n",
       " 'action',\n",
       " 'policy_info',\n",
       " 'next_step_type',\n",
       " 'reward',\n",
       " 'discount')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec._fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e308b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_step(environment, policy, buffer):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "  for _ in range(steps):\n",
    "    collect_step(env, policy, buffer)\n",
    "\n",
    "collect_data(train_env, random_policy, replay_buffer, initial_collect_steps)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations. \n",
    "# For more details see tutorial 4 or the drivers module.\n",
    "# https://github.com/tensorflow/agents/blob/master/docs/tutorials/4_drivers_tutorial.ipynb \n",
    "# https://www.tensorflow.org/agents/api_docs/python/tf_agents/drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a15d4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to peel one of these off and inspect it.\n",
    "# iter(replay_buffer.as_dataset()).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a56f40bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (Trajectory(\n",
       "{action: (64, 2),\n",
       " discount: (64, 2),\n",
       " next_step_type: (64, 2),\n",
       " observation: (64, 2, 4),\n",
       " policy_info: (),\n",
       " reward: (64, 2),\n",
       " step_type: (64, 2)}), BufferInfo(ids=(64, 2), probabilities=(64,))), types: (Trajectory(\n",
       "{action: tf.int64,\n",
       " discount: tf.float32,\n",
       " next_step_type: tf.int32,\n",
       " observation: tf.float32,\n",
       " policy_info: (),\n",
       " reward: tf.float32,\n",
       " step_type: tf.int32}), BufferInfo(ids=tf.int64, probabilities=tf.float32))>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a605c8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000002215CD9A7F0>\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "279cc04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see what the dataset iterator is feeding to the agent.\n",
    "# Compare this representation of replay data \n",
    "# to the collection of individual trajectories shown earlier.\n",
    "\n",
    "# iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28d97bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Viewer.__del__ at 0x00000220D441F820>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\poojai1\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 165, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\poojai1\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 83, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\poojai1\\Anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 319, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\poojai1\\Anaconda3\\lib\\site-packages\\pyglet\\window\\__init__.py\", line 838, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\poojai1\\Anaconda3\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: <weakref at 0x00000220D43CD4F0; to 'Win32Window' at 0x00000220D3F9EF40>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 200: loss = 15.136507034301758\n",
      "step = 400: loss = 4.012071132659912\n",
      "step = 600: loss = 35.83407974243164\n",
      "step = 800: loss = 104.96697235107422\n",
      "step = 1000: loss = 9.516736030578613\n",
      "step = 1000: Average Return = 62.70000076293945\n",
      "step = 1200: loss = 13.363763809204102\n",
      "step = 1400: loss = 14.825506210327148\n",
      "step = 1600: loss = 16.830751419067383\n",
      "step = 1800: loss = 93.49717712402344\n",
      "step = 2000: loss = 412.6571044921875\n",
      "step = 2000: Average Return = 200.0\n",
      "step = 2200: loss = 31.95194435119629\n",
      "step = 2400: loss = 141.32681274414062\n",
      "step = 2600: loss = 259.7391357421875\n",
      "step = 2800: loss = 979.8907470703125\n",
      "step = 3000: loss = 456.42340087890625\n",
      "step = 3000: Average Return = 200.0\n",
      "step = 3200: loss = 494.4441833496094\n",
      "step = 3400: loss = 552.9183349609375\n",
      "step = 3600: loss = 74113.4296875\n",
      "step = 3800: loss = 4335.1591796875\n",
      "step = 4000: loss = 7209.3603515625\n",
      "step = 4000: Average Return = 200.0\n",
      "step = 4200: loss = 8659.001953125\n",
      "step = 4400: loss = 41241.6875\n",
      "step = 4600: loss = 65958.1640625\n",
      "step = 4800: loss = 45650.5078125\n",
      "step = 5000: loss = 227221.6875\n",
      "step = 5000: Average Return = 200.0\n",
      "step = 5200: loss = 348382.0\n",
      "step = 5400: loss = 326059.65625\n",
      "step = 5600: loss = 704884.875\n",
      "step = 5800: loss = 544056.125\n",
      "step = 6000: loss = 1038042.75\n",
      "step = 6000: Average Return = 200.0\n",
      "step = 6200: loss = 1267510.0\n",
      "step = 6400: loss = 65943900.0\n",
      "step = 6600: loss = 966328.25\n",
      "step = 6800: loss = 1549398.75\n",
      "step = 7000: loss = 3054281.75\n",
      "step = 7000: Average Return = 200.0\n",
      "step = 7200: loss = 3379316.0\n",
      "step = 7400: loss = 3897788.0\n",
      "step = 7600: loss = 5491173.0\n",
      "step = 7800: loss = 6354840.0\n",
      "step = 8000: loss = 11691861.0\n",
      "step = 8000: Average Return = 200.0\n",
      "step = 8200: loss = 12833938.0\n",
      "step = 8400: loss = 7916797.0\n",
      "step = 8600: loss = 13959994.0\n",
      "step = 8800: loss = 10544726.0\n",
      "step = 9000: loss = 17310346.0\n",
      "step = 9000: Average Return = 200.0\n",
      "step = 9200: loss = 21015324.0\n",
      "step = 9400: loss = 47979280.0\n",
      "step = 9600: loss = 56617568.0\n",
      "step = 9800: loss = 47800544.0\n",
      "step = 10000: loss = 95323952.0\n",
      "step = 10000: Average Return = 200.0\n",
      "step = 10200: loss = 19296340.0\n",
      "step = 10400: loss = 82000400.0\n",
      "step = 10600: loss = 86447520.0\n",
      "step = 10800: loss = 65425656.0\n",
      "step = 11000: loss = 96453840.0\n",
      "step = 11000: Average Return = 200.0\n",
      "step = 11200: loss = 99744312.0\n",
      "step = 11400: loss = 56538680.0\n",
      "step = 11600: loss = 209453472.0\n",
      "step = 11800: loss = 113663824.0\n",
      "step = 12000: loss = 79753648.0\n",
      "step = 12000: Average Return = 200.0\n",
      "step = 12200: loss = 153723136.0\n",
      "step = 12400: loss = 67579984.0\n",
      "step = 12600: loss = 63435400.0\n",
      "step = 12800: loss = 52236580.0\n",
      "step = 13000: loss = 67800600.0\n",
      "step = 13000: Average Return = 200.0\n",
      "step = 13200: loss = 144186848.0\n",
      "step = 13400: loss = 137975568.0\n",
      "step = 13600: loss = 193407120.0\n",
      "step = 13800: loss = 232073888.0\n",
      "step = 14000: loss = 135817984.0\n",
      "step = 14000: Average Return = 200.0\n",
      "step = 14200: loss = 348335360.0\n",
      "step = 14400: loss = 19133003776.0\n",
      "step = 14600: loss = 209790048.0\n",
      "step = 14800: loss = 161402288.0\n",
      "step = 15000: loss = 484502272.0\n",
      "step = 15000: Average Return = 200.0\n",
      "step = 15200: loss = 301627968.0\n",
      "step = 15400: loss = 256171776.0\n",
      "step = 15600: loss = 290593920.0\n",
      "step = 15800: loss = 292547776.0\n",
      "step = 16000: loss = 119405880.0\n",
      "step = 16000: Average Return = 154.5\n",
      "step = 16200: loss = 495237792.0\n",
      "step = 16400: loss = 561540352.0\n",
      "step = 16600: loss = 138808928.0\n",
      "step = 16800: loss = 596249152.0\n",
      "step = 17000: loss = 408223424.0\n",
      "step = 17000: Average Return = 200.0\n",
      "step = 17200: loss = 392868352.0\n",
      "step = 17400: loss = 650790016.0\n",
      "step = 17600: loss = 751520640.0\n",
      "step = 17800: loss = 392332096.0\n",
      "step = 18000: loss = 291547840.0\n",
      "step = 18000: Average Return = 200.0\n",
      "step = 18200: loss = 204815216.0\n",
      "step = 18400: loss = 268126624.0\n",
      "step = 18600: loss = 492229600.0\n",
      "step = 18800: loss = 686470912.0\n",
      "step = 19000: loss = 345887104.0\n",
      "step = 19000: Average Return = 200.0\n",
      "step = 19200: loss = 316545728.0\n",
      "step = 19400: loss = 566229056.0\n",
      "step = 19600: loss = 549484224.0\n",
      "step = 19800: loss = 408342848.0\n",
      "step = 20000: loss = 456960320.0\n",
      "step = 20000: Average Return = 200.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  collect_data(train_env, agent.collect_policy, replay_buffer, collect_steps_per_iteration)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "177971a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_return(eval_env, agent.policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0dce7507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.44499959945678746, 250.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6872c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embeds videos into the notebook for visualization\n",
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ee2d2d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "To use the imageio ffmpeg plugin you need to 'pip install imageio-ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py\u001b[0m in \u001b[0;36m_get_ffmpeg_api\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[1;32mimport\u001b[0m \u001b[0mimageio_ffmpeg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imageio_ffmpeg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-7853964a9865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcreate_policy_eval_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"trained-agent\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-67-7853964a9865>\u001b[0m in \u001b[0;36mcreate_policy_eval_video\u001b[1;34m(policy, filename, num_episodes, fps)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_policy_eval_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".mp4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mtime_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_writer\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;31m# Return its writer object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\core\\format.py\u001b[0m in \u001b[0;36mget_writer\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;34m\"Format %s cannot write in %s mode\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             )\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcan_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\core\\format.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, format, request)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;31m# Open the reader/writer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, fps, codec, bitrate, pixelformat, ffmpeg_params, input_params, output_params, ffmpeg_log_level, quality, macro_block_size)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mmacro_block_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         ):\n\u001b[1;32m--> 525\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ffmpeg_api\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_ffmpeg_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pix_fmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py\u001b[0m in \u001b[0;36m_get_ffmpeg_api\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mimageio_ffmpeg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             raise ImportError(\n\u001b[0m\u001b[0;32m     62\u001b[0m                 \u001b[1;34m\"To use the imageio ffmpeg plugin you need to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;34m\"'pip install imageio-ffmpeg'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: To use the imageio ffmpeg plugin you need to 'pip install imageio-ffmpeg'"
     ]
    }
   ],
   "source": [
    "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
    "  filename = filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = eval_env.reset()\n",
    "      video.append_data(eval_py_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = eval_env.step(action_step.action)\n",
    "        video.append_data(eval_py_env.render())\n",
    "  return embed_mp4(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "create_policy_eval_video(agent.policy, \"trained-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d39dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trained agent\n",
    "create_policy_eval_video(agent.policy, \"trained-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random agent\n",
    "create_policy_eval_video(random_policy, \"random-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b695e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
